{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Тензоры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скаляры (тензоры нулевого ранга)\n",
    "x = np.array(12)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Векторы (тензоры первого ранга)\n",
    "x = np.array([12, 3, 6, 14])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Матрицы (тензоры второго ранга)\n",
    "x = np.array([[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ключевые атрибуты тензора\n",
    "\n",
    "1) Количество осей (ранг) — например, трехмерный тензор имеет три оси, а матрица — две. В библиотеках для Python, таких как Numpy, этот атрибут тензоров имеет имя ndim.\n",
    "\n",
    "2) Форма — кортеж целых чисел, описывающих количество измерений на каждой оси тензора. (shape)\n",
    "\n",
    "3) Тип данных (обычно в библиотеках для Python ему дается имя dtype) — это тип данных, содержащихся в тензоре; например, тензор может иметь тип float32, uint8, float64 и др. (dtype)\n",
    "\n",
    "## Пакеты данных\n",
    "\n",
    "Модели глубокого обучения не обрабатывают весь набор данных целиком; они разбивают его на небольшие пакеты (batch).\n",
    "\n",
    "1) векторные данные — двумерные тензоры с формой (образцы, признаки);\n",
    "\n",
    "2) временные ряды или последовательности — трехмерные тензоры с формой (образцы, метки_времени, признаки);\n",
    "\n",
    "3) изображения — четырехмерные тензоры с формой (образцы, высота, ширина, цвет) или с формой (образцы, цвет, высота, ширина);\n",
    "\n",
    "4) видео — пятимерные тензоры с формой (образцы, кадры, высота, ширина, цвет) или с формой (образцы, кадры, цвет, высота, ширина)\n",
    "\n",
    "# 2) Анатомия нейронной сети\n",
    "\n",
    "1) слои, которые объединяются в сеть (или модель);\n",
    "\n",
    "2) исходных данных и соответствующих им целях;\n",
    "\n",
    "3) функции потерь, которая определяет сигнал обратной связи, используемый для обучения;\n",
    "\n",
    "4) оптимизатор, определяющий, как происходит обучение. Реализует конкретный вариант стохастического градиентного спуска (Stochastic Gradient Descent, SGD)\n",
    "\n",
    "## 2.1) Cлои\n",
    "\n",
    "1)векторные данные, хранящиеся в двумерных тензорах с формой (образцы, признаки), часто обрабатываются плотно связанными слоями, которые также называют полносвязными, или плотными, слоями (класс Dense в Keras). \n",
    "\n",
    "2)Временные ряды данных хранятся в трехмерных тензорах с формой (образцы, метки_времени, признаки) и обычно обрабатываются рекуррентными слоями, такими как LSTM. \n",
    "\n",
    "3)Изображения хранятся в четырехмерных тензорах и обычно обрабатываются двумерными сверточными слоями (Conv2D).\n",
    "\n",
    "## 2.2) Cтруктура модели\n",
    "\n",
    "Модель можно определить двумя способами: с использованием класса Sequential (только для линейного стека слоев — наиболее популярная архитектура сетей в настоящее время) или функционального API (для ориентированного ациклического графа слоев, позволяющего конструировать произвольные архитектуры)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential()\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API (позволяет манипулировать данными в тензорах, которые обрабатывает модель, \n",
    "#     и применять слои к этим тензорам, как если бы они были функциями.)\n",
    "input_tensor = layers.Input(shape=(784,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После определения архитектуры уже неважно, используете вы модель Sequential или функциональный API. В обоих случаях далее выполняются одинаковые шаги.\n",
    "Настройка процесса обучения производится на этапе компиляции. При этом задаются оптимизатор и функция(-и) потерь, которые должны использоваться моделью, а также все метрики для мониторинга во время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix]) #загрузка весов в слой 0\n",
    "model.layers[0].trainable = False # замораживание весов слоя 0 (не меняются в обучении)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() #структура итоговой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(input_tensor, target_tensor, batch_size=128, epochs=10, validation_data=(x_val, y_val))\n",
    "history_dict = history.history #словарь оценок на валидации и обчении \n",
    "history_dict.keys()\n",
    "\n",
    "#history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=30, \n",
    "#                              validation_data=validation_generator, validation_steps=50) Обучение если на вход подается генераор, а не тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5') #cохранение весов модели\n",
    "model.save('model.h5') #cохранение всей модели включая оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model.h5')  #загрузка модели\n",
    "# model.load_weights(checkpoint_path) \n",
    "# checkpoint_path - путь к файлу с моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score, test_score = model.evaluate(test_data, test_targets) #оценка модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test) #предсказание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Обзор соответствий между некоторыми входными модальностями и сетевыми архитектурами:\n",
    "\n",
    "1) Векторные данные — полносвязные сети (слои Dense).\n",
    "\n",
    "2) Изображения — двумерные сверточные сети.\n",
    "\n",
    "3) Звуки (например, сигналы волновой формы) — одномерные сверточные сети (предпочтительно) или рекуррентные сети.\n",
    "\n",
    "4) Текстовые данные — одномерные сверточные сети (предпочтительно) или рекуррентные сети.\n",
    "\n",
    "5) Временные последовательности — рекуррентные сети (предпочтительно) или одномерные сверточные сети.\n",
    "\n",
    "6) Другие виды последовательных данных — рекуррентные сети или одномерные сверточные сети. Рекуррентные сети предпочтительнее, если упорядоченность данных имеет большое значение (например, для временных последовательностей, но не для текста).\n",
    "\n",
    "7) Видеоданные — трехмерные сверточные сети (если необходимо захватывать эффекты движения) или комбинация двумерной сверточной сети, действующей на уровне кадров для извлечения признаков, с последующей обработкой рекуррентной сетью или одномерной сверточной сетью для обработки получающихся последовательностей.\n",
    "\n",
    "8) Объемные данные — трехмерные сверточные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.4) LAYERS (from tensorflow.keras import layers)\n",
    "\n",
    "#### 2.4.1) layers.Dense (Полносвязный слой)\n",
    "\n",
    "Обрабатывают векторы — одномерные массивы, тогда как текущий выход является трехмерным тензором.\n",
    "\n",
    "#### 2.4.2)  Сверточные слои\n",
    "\n",
    "##### 2.4.2.1. layers.Conv2D (Сверточный слой)\n",
    "\n",
    "Выводят трехмерный тензор с формой (высота, ширина, число_фильтров)\n",
    "\n",
    "layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))\n",
    "\n",
    "32 - размер выходной глубины слоя (число фильтров)\n",
    "\n",
    "(3,3) - размер окна\n",
    "\n",
    "input_shape=(28, 28, 1) - ширина x высота x число_каналов_цветов\n",
    "\n",
    "padding = 'valid'/'same' - дополнение, дополняет так, чтобы выходная карта признаков имела ту же ширину и высоту, что и входная\n",
    "\n",
    "##### 2.4.2.2. layers.Conv1D ( Одномерный сверточный слой)\n",
    "\n",
    "Принимает на входе трехмерные тензоры с формой (образцы, время, признаки) и возвращает трехмерные тензоры с той же формой. Окно свертки — это одномерное окно на оси времени: оси с индексом 1 во входном тензоре.\n",
    "\n",
    "#### 2.4.3) layers.MaxPooling2D\n",
    "\n",
    "Используется для уменьшения разрешения карты признаков. Из входной карты признаков извлекается окно, и из него выбирается максимальное значение для каждого канала. Уменьшение разрешения используется для уменьшения количества коэффициентов в карте признаков для обработки, а также внедрения иерархий пространственных фильтров путем создания последовательных слоев свертки для просмотра все более крупных окон\n",
    "\n",
    "Выводят трехмерный тензор с формой (высота, ширина, каналы)\n",
    "\n",
    "#### 2.4.4) layers.Flatten()\n",
    "\n",
    "Преобразует выход предыдущего слоя в одномерный вектор\n",
    "\n",
    "#### 2.4.5) layers.Embedding(колличество возможных токенов, размерность пространства)\n",
    "\n",
    "Слой Embedding лучше всего воспринимать как словарь, отображающий целочисленные индексы (обозначающие конкретные слова) в плотные векторы. Он принимает целые числа на входе, отыскивает их во внутреннем словаре и возвращает соответствующие векторы.\n",
    "\n",
    "Слой Embedding получает на входе двумерный тензор с целыми числами и с формой (образцы, длина_последовательности), каждый элемент которого является последовательностью целых чисел.\n",
    "\n",
    "Этот слой возвращает трехмерный тензор с вещественными числами и с формой (образцы, длина_последовательности, размерность_векторного_представления). Такой трехмерный тензор можно затем обработать слоем RNN или одномерным сверточным слоем.\n",
    "\n",
    "#### 2.4.6)layers.SimpleRNN(return_sequences=) (рекуррентный слой )\n",
    "\n",
    "return_sequences - управляет режимом возврата данных, либо вернуть только конечный ответ, либо возвращать полные последовательности результатов для всех временных интервалов\n",
    "\n",
    "#### 2.4.7) layers.LSTM() (рекуррентный слой )\n",
    "\n",
    "Позволяет прошлой информации повторно внедриться в процесс обучения и оказать сопротивление проблеме затухания градиента.\n",
    "\n",
    "Используется в задачах обработки естественного языка,таких как:  диалоговые системы типа «вопрос/ответ» и в машинном переводе.\n",
    "\n",
    "#### 2.4.8) layers.Bidirectional(layers.LSTM()) (двунаправленный слой, в аргументе принимает рекуррентный слой)\n",
    "\n",
    "#### 2.4.9) layers.BatchNormalization() (Слой Пакетной нормализации)\n",
    "\n",
    "Может адаптивно нормализовать данные, даже если среднее и дисперсия изменяются во время обучения. Его принцип действия основан на вычислении экспоненциального скользящего среднего и дисперсии данных, наблюдаемых в процессе обучения. Основное назначение пакетной нормализации — помочь распространению градиента подобно остаточным связям и дать возможность создавать более глубокие сети.\n",
    "\n",
    "Обычно слой BatchNormalization используется после сверточного или полносвязного слоя\n",
    "\n",
    "Слой BatchNormalization принимает аргумент axis, определяющий ось признаков для нормализации. По умолчанию этот аргумент принимает значение –1, что соответствует последней оси во входном тензоре. Это правильное значение, когда используются слои Dense, Conv1D, рекуррентные слои и слои Conv2D со значением \"channels_last\" в аргументе data_format. Но в слоях Conv2D со значением \"channels_first\" в аргументе data_format ось признаков — это ось с индексом 1; поэтому в таких случаях слою BatchNormalization следует передавать число 1 аргументе axis.\n",
    "\n",
    "#### 2.4.10) layers.SeparableConv2D() (слой раздельной свертки по глубине (современный аналог слоя Conv)\n",
    "\n",
    "Этот слой выполняет пространственную свертку каждого канала во входных данных в отдельности перед смешиванием выходных каналов посредством поточечной свертки (свертки 1 × 1), как показано на рис. 7.16. Это эквивалентно раздельному выделению пространственных и канальных признаков, что оправданно, если предполагается сильная корреляция пространственных местоположений на входе, но разные каналы практически не зависят друг от друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5) ACTIVATION (ФУНКЦИИ АКТИВАЦИИ СЛОЕВ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1) activation='relu'\n",
    "\n",
    "Функция relu (rectified linear unit — блок линейной ректификации) используется для преобразования отрицательных значений в ноль\n",
    "\n",
    "#### 2.5.2) activation='sigmoid'\n",
    "\n",
    "Cигмоидная функция рассредоточивает произвольные значения по интервалу [0, 1], возвращая значения, которые можно интерпретировать как вероятность.\n",
    "\n",
    "#### 2.5.3) activation='softmax'\n",
    "\n",
    "Функция активации softmax  означает, что сеть будет выводить распределение вероятностей по N разным классам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6) LOSS (from tensorflow.keras import losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.1) loss='binary_crossentropy'  (Для классификации с двумя классами.)\n",
    "\n",
    "#### 2.6.2) loss='categorical_crossentropy'  (Для многоклассовой классификации.)\n",
    "\n",
    "Определяет расстояние между распределениями вероятностей: распределением вероятности на выходе сети и истинным распределением меток. Минимизируя расстояние между этими двумя распределениями, мы учим сеть выводить результат, максимально близкий к истинным меткам. (используется для категориальных меток закодированных методом one-hot)\n",
    "\n",
    "#### 2.6.3) loss='sparse_categorical_crossentropy' (Для многоклассовой классификации.)\n",
    "\n",
    "Эту функцию следует использовать с целочисленными метками классов (без кодировки)\n",
    "\n",
    "#### 2.6.4) loss='mse' (Для регрессии)\n",
    "\n",
    "Mean squared error (среднеквадратичная ошибка), вычисляет квадрат разности между предсказанными и целевыми значениями.\n",
    "\n",
    "#### 2.6.5) loss = 'mae' (Для регрессии)\n",
    "\n",
    "Средняя абсолютная ошибка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7) METRICS (from tensorflow.keras import metrics)\n",
    "\n",
    "#### 2.7.1) metrics=['mae'] (средняя абсолютная ошибка). \n",
    "\n",
    "Это абсолютное значение разности между предсказанными и целевыми значениями.\n",
    "\n",
    "#### 2.7.2) metrics=['acc'] (точность)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8) OPTIMIZER\n",
    "\n",
    "Показывает каким образом обновляется модель на основе входных данных и функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Предварительная обработка данных для нейроных сетей\n",
    "\n",
    "### 3.1) Нормализация значений\n",
    "\n",
    "### 3.2) Обработка недостающих значений\n",
    "\n",
    "Вообще в случае с нейронными сетями вполне безопасно заменить недостающие входные значения нулями, при условии, что 0 не является осмысленным значением. Обрабатывая данные, сеть поймет, что 0 означает отсутствие данных, и будет игнорировать это значение.\n",
    "\n",
    "### 3.3) Конструирование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Методы регуляризации нейронной сети\n",
    "\n",
    "### 4.1) Уменьшение размеров сети\n",
    "\n",
    "Самый простой способ предотвратить переобучение — уменьшить размер модели: количество изучаемых параметров в модели (определяется количеством слоев и количеством нейронов (размерностью) в каждом слое).\n",
    "\n",
    "В общем случае процесс поиска подходящего размера модели должен начинаться с относительно небольшого количества слоев и параметров, а затем размеры слоев и их количество должны постепенно увеличиваться, пока не произойдет увеличение потерь на проверочных данных.\n",
    "\n",
    "### 4.2) Добавление регуляризации весов\n",
    "\n",
    "Типичный способ смягчения проблемы переобучения заключается в уменьшении сложности сети путем ограничения значений ее весовых коэффициентов, что делает их распределение более равномерным.\n",
    "\n",
    "L1-регуляризация (L1 regularization) — добавляемый штраф прямо пропорционален абсолютным значениям весовых коэффициентов (L1-норма весов).\n",
    "\n",
    "L2-регуляризация (L2 regularization) — добавляемый штраф пропорционален квадратам значений весовых коэффициентов (L2-норма весов). В контексте нейронных сетей L2-регуляризация также называется сокращением весов (weight decay).\n",
    "\n",
    "В Keras регуляризация весов осуществляется путем передачи в слои именованных аргументов с экземплярами регуляризаторов весов.\n",
    "##### model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,)))\n",
    "\n",
    "Обратите внимание: так как штраф добавляется только на этапе обучения, величина потерь сети на этапе обучения будет намного выше, чем на этапе контроля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разные регуляризаторы, доступные в Keras\n",
    "from keras import regularizers\n",
    "regularizers.l1(0.001) L1-регуляризация\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001) Объединенная L1- и L2-регуляризация\n",
    "\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Добавление прореживания\n",
    "\n",
    "Прореживание, которое применяется к слою, заключается в удалении (присваивании нуля) случайно выбираемым признакам на этапе обучения.\n",
    "\n",
    "Представьте, что в процессе обучения некоторый уровень для данного образца на входе в нормальной ситуации возвращает вектор [0,2, 0,5, 1,3, 0,8, 1,1]. После применения прореживания некоторые элементы вектора получают нулевое значение: например, [0, 0,5, 1,3, 0, 1,1]. \n",
    "\n",
    "Коэффициент прореживания — это доля обнуляемых признаков; обычно он выбирается в диапазоне от 0,2 до 0,5. \n",
    "\n",
    "На этапе тестирования прореживание не производится; вместо этого выходные значения уровня уменьшаются на коэффициент, равный коэффициенту прореживания, чтобы компенсировать разницу в активности признаков на этапах тестирования и обучения.\n",
    "\n",
    "layer_output *= np.random.randint(0, high=2, size=layer_output.shape) - На этапе обучения обнуляется 50% признаков в выводе\n",
    "layer_output *= 0.5 - На этапе тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В Keras добавить прореживание в сеть можно посредством уровня Dropout, \n",
    "# который обрабатывает результаты работы слоя, стоящего непосредственно перед ним:\n",
    "model.add(layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Увеличить объем тренировочных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Стратегии решения задачи классификации изображений с обучением на небольших наборах данных\n",
    "\n",
    "1)обучение малой модели с нуля, расширение данных\n",
    "\n",
    "2)выделение признаков с использованием предварительно обученной модели и дообучение этой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cписок моделей классификации изображений (все они предварительно обучены на наборе ImageNet), доступных в keras .applications\n",
    "\n",
    "1) Xception\n",
    "\n",
    "2) Inception V3\n",
    "\n",
    "3) ResNet50\n",
    "\n",
    "4) VGG16\n",
    "\n",
    "5) VGG19\n",
    "\n",
    "6) MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Глубокое обучение для текста и последовательностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Обработка текстовых данных\n",
    "\n",
    "#### 6.1.1) Прямое кодирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000) \n",
    "tokenizer.fit_on_texts(samples) #samples - масив с текстами\n",
    "sequences = tokenizer.texts_to_sequences(samples) # преобразование текстов в списки целочисленных индексов\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary') # получение прямых бинарных представлений\n",
    "word_index = tokenizer.word_index #вычисленные индексы слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2) Векторное представление слов\n",
    "\n",
    "В отличие от векторов, полученных прямым кодированием, векторные представления слов конструируются из данных. Векторное представление слов позволяет уместить больший объем информации в меньшее число измерений. Геометрические отношения между векторами слов должны отражать семантические связи между соответствующими им словами. Как предполагается, векторные представления слов должны отображать человеческий язык в геометрическое пространство.\n",
    "\n",
    "Получить векторные представления слов можно двумя способами:\n",
    "\n",
    "1) Конструировать векторные представления в процессе решения основной задачи (такой, как классификация документа или определение эмоциональной окраски). В этом случае изначально создаются случайные векторы слов, которые затем постепенно конструируются (обучаются), как это происходит с весами нейронной сети.\n",
    "\n",
    "2) Загрузить в модель векторные представления, полученные с использованием другой задачи машинного обучения, отличной от решаемой. Такие представления называют предварительно обученными векторными представлениями слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Рекуррентные сети (RNN)\n",
    "\n",
    "### Улучшенные методы использования рекуррентных нейронных сетей\n",
    "\n",
    "1) рекуррентное прореживание — особый встроенный способ использования прореживания для борьбы с переобучением в рекуррентных слоях;\n",
    "\n",
    "2) наложение рекуррентных слоев — способ увеличения репрезентативности сети (за счет увеличения объема вычислений);\n",
    "\n",
    "3) двунаправленные рекуррентные слои — представляют одну и ту же информацию в рекуррентной сети разными способами, повышая точность и ослабляя проблемы, связанные с забыванием."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Функциональный API KERAS\n",
    "\n",
    "Функциональный API позволяет напрямую манипулировать тензорами и использовать уровни как функции, которые принимают и возвращают тензоры. Для создания моделей с несколькими входами, моделей с несколькими выходами и графоподобных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Обратные вызовы для воздействия на модель в ходе обучения\n",
    "\n",
    "Обратный вызов — это объект (экземпляр класса, реализующего конкретные методы), который передается в модель через вызов fit и который будет вызываться моделью в разные моменты в процессе обучения. Он имеет доступ ко всей информации о состоянии модели и ее качестве и может предпринимать следующие действия: прерывать обучение, сохранять модели, загружать разные наборы весов или как-то иначе изменять состояние модели.\n",
    "\n",
    "Вот несколько примеров использования обратных вызовов:\n",
    "\n",
    "1) фиксация состояния модели в контрольных точках — сохранение текущих весов модели в разные моменты в ходе обучения;\n",
    "\n",
    "2) ранняя остановка — прерывание обучения, когда оценка потерь на проверочных данных перестает улучшаться (и, конечно, сохранение лучшего варианта модели, полученного в ходе обучения);\n",
    "\n",
    "3) динамическая корректировка значений некоторых параметров в процессе обучения, например шага обучения оптимизатора;\n",
    "\n",
    "4) журналирование оценок для обучающего и проверочного наборов данных в ходе обучения или визуализация представлений, получаемых моделью, по мере их обновления — индикатор выполнения в Keras, с которым вы уже знакомы, — обратный вызов!\n",
    "\n",
    "Модуль keras.callbacks включает в себя ряд встроенных обратных вызовов. Вот далеко не полный список:\n",
    "\n",
    ">keras.callbacks.ModelCheckpoint\n",
    "\n",
    ">keras.callbacks.EarlyStopping\n",
    "\n",
    ">keras.callbacks.LearningRateScheduler\n",
    "\n",
    ">keras.callbacks.ReduceLROnPlateau\n",
    "\n",
    ">keras.callbacks.CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Тренировочные датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters #классификация новостных лент\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb #классификация отзывов к фильмам\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) #сохраняем только 10000 самых популярных слов\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen) # Преобразование списков целых чисел в двумерный тензор с целыми числами и с формой (образцы, максимальная_длина)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist # изображения рукописных цифр\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Изображения являются 28х28 массивами NumPy, где значение пикселей варьируется от 0 до 255.\n",
    "# Метки (labels) - это массив целых чисел от 0 до 9. Они соответствуют классам одежды изображенной на картинках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11) from tensorflow.keras.utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels) # one-hot кодирование категориальных признков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12) from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer #для обработки текстов\n",
    "texts # список, где каждый элемент текст\n",
    "max_words = 10000 #Рассмотрение только 10 000 наиболее часто используемых слов\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts) #выделение корпуса наиболее частых слов из текстов\n",
    "sequences = tokenizer.texts_to_sequences(texts) #преобразование текстов в последовательность индексов наиболее частых слов\n",
    "word_index = tokenizer.word_index #словарь слово - индекс\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #для обработки последовательностей\n",
    "maxlen = 100 \n",
    "data = pad_sequences(sequences, maxlen=maxlen) #отсечение в каждом элементе списка sequences всех элементов c индексом больше maxlen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #для обработки изображений\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255) #делает одни и те же действия с каждым изображением в заданной директории\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=20, class_mode='binary') \n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,\n",
    "                             zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "img_path #путь к изображению\n",
    "img = image.load_img(img_path, target_size=(150, 150)) #чтение изображения и его размеров\n",
    "x = image.img_to_array(img)  #преобразование его в массив\n",
    "plt.imshow(image.array_to_img(x)) #вывод изображения\n",
    "img.save(os.path.join(save_dir, 'name.png')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13) from tensorflow.keras.applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "#Аргумент weights определяет источник весов для инициализации модели.\n",
    "#Аргумент include_top определяет необходимость подключения к сети полносвязного классификатора. По умолчанию этот полносвязный классификатор соответствует 1000 классов из ImageNet. Так как мы намереваемся использовать свой полносвязный классификатор (только с двумя классами: cat и dog), мы не будем подключать его.\n",
    "#Аргумент input_shape определяет форму тензоров с изображениями, которые будут подаваться на вход сети. Это необязательный аргумент: если опустить его, сеть сможет обрабатывать изображения любого размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "model = inception_v3.InceptionV3(weights='imagenet', include_top=False) #Конструирование сети Inception V3 без сверточной основы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14) from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
