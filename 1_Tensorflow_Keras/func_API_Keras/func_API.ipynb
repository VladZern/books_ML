{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функциональный API\n",
    "\n",
    "Функциональный API позволяет напрямую манипулировать тензорами и использовать уровни как функции, которые принимают и возвращают тензоры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, layers\n",
    "input_tensor = Input(shape=(32,)) # Тензор\n",
    "dense = layers.Dense(32, activation='relu') # Слой — это функция\n",
    "output_tensor = dense(input_tensor) # Вызываемый слой может принимать и возвращать тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#обычная sequential model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "seq_model = Sequential() \n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ее функциональный эквивалент\n",
    "input_tensor = Input(shape=(64,)) \n",
    "x = layers.Dense(32, activation='relu')(input_tensor) \n",
    "x = layers.Dense(32, activation='relu')(x) \n",
    "output_tensor = layers.Dense(10, activation='softmax')(x) \n",
    "\n",
    "model = Model(input_tensor, output_tensor) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 12.3695\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 17us/sample - loss: 13.4238\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 17us/sample - loss: 15.2521\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 20us/sample - loss: 17.8404\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 20us/sample - loss: 21.1393\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 20us/sample - loss: 25.0042\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 16us/sample - loss: 29.4758\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 21us/sample - loss: 34.4236\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 20us/sample - loss: 40.0487\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 18us/sample - loss: 45.9325\n",
      "1000/1000 [==============================] - 0s 141us/sample - loss: 49.3782\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy') #обучение функциональной модели\n",
    "import numpy as np \n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128) \n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели с несколькими входами\n",
    "\n",
    "Функциональный API можно использовать для создания моделей с несколькими входами. Обычно такие модели в какой-то момент объединяют свои входные ветви, используя слой, способный объединить несколько тензоров: сложением, слиянием или как-то иначе. Часто для этого используются операции слияния, реализованные в Keras, такие как keras.layers.add, keras.layers.concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типичная модель «вопрос/ответ» имеет два входа: вопрос на естественном языке и фрагмент текста (например, новостная статья) с информацией, которая будет использоваться для ответа на вопрос. Опираясь на эти данные, модель должна вернуть ответ: в простейшем случае это может быть ответ, состоящий из одного слова, полученного применением классификатора softmax к некоторому предопределенному словарю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras.models import Model\n",
    "from  tensorflow.keras import layers\n",
    "from  tensorflow.keras import Input\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text') #текстовый вход (вход 1)\n",
    "embedded_text = layers.Embedding( text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question') #преобразование вопроса (вход 2)\n",
    "embedded_question = layers.Embedding( question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1) #объединение\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated) #ответ (выход модели)\n",
    "\n",
    "model = Model([text_input, question_input], answer) \n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь встает вопрос обучения модели с двумя входами. Для этого можно использовать два разных API: можно передать модели список массивов Numpy или словарь, отображающий имена входов в массивы Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 8s 8ms/sample - loss: 6.2144 - acc: 0.0020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 963us/sample - loss: 6.1949 - acc: 0.0390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 958us/sample - loss: 6.1331 - acc: 0.0050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 949us/sample - loss: 6.0494 - acc: 0.0060\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 965us/sample - loss: 5.9954 - acc: 0.0070\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 980us/sample - loss: 5.9209 - acc: 0.0080\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 964us/sample - loss: 5.8163 - acc: 0.0160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 964us/sample - loss: 5.7378 - acc: 0.0290\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 981us/sample - loss: 5.6572 - acc: 0.0510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 965us/sample - loss: 5.5820 - acc: 0.0630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x100d6988>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "answers = np.zeros(shape=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "indices = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "for i, x in enumerate(answers): \n",
    "    x[indices[i]] = 1\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128) \n",
    "#model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели с несколькими выходами\n",
    "\n",
    "Функциональный API также можно использовать для создания моделей с несколькими выходами (или головами). Простейшим примером может служить сеть, пытающаяся одновременно предсказать разные свойства данных, например принимающая на входе последовательность постов из социальной сети от некоторой анонимной персоны и пытающаяся предсказать характеристики этой персоны, такие как возраст, пол и уровень доходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x) #выход1\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x) #выход2\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x) #выход3\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что для обучения такой модели необходима возможность задавать разные функции потерь для разных выходов: например, определение возраста — это задача скалярной регрессии, но определение пола — задача бинарной классификации, требующая отдельной процедуры обучения. Однако из-за того, что градиентный спуск требует минимизации скаляра, эти функции потерь должны объединяться в единственное значение. Простейший способ объединения потерь — их суммирование. В Keras для этого можно передать функции compile список или словарь с разными объектами для разных выходов; в результате значения потерь будут суммироваться в общее значение потери, которое будет минимизироваться в ходе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "# model.compile(optimizer='rmsprop', loss={'age': 'mse', 'income': 'categorical_crossentropy', 'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание: несбалансированные вклады потерь приведут к созданию представления, оптимизированного преимущественно для задачи с наибольшей потерей, в ущерб другим задачам. Чтобы исправить эту проблему, можно присвоить разные степени важности значениям потерь, вносящим вклад в общую потерю. Это может пригодиться, когда значения потерь имеют разные масштабы. Например, средняя квадратичная ошибка (Mean Squared Error, MSE), используемая как функция потерь в задаче определения возраста, обычно принимает значение около 3–5, тогда как перекрестная энтропия, используемая в задаче определения пола, может колебаться около величины 0,1. Чтобы в такой ситуации сбалансировать вклад разных потерь, можно присвоить вес 10 перекрестной энтропии и вес 0,25 — оценке MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], loss_weights=[0.25, 1., 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(post, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64) \n",
    "# model.fit(posts, {'age': age_targets, 'income': income_targets, 'gender': gender_targets}, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ориентированные ациклические графы уровней\n",
    "С помощью функционального API можно не только создавать модели с несколькими входами и выходами, но также конструировать сети со сложной внутренней топологией. Фреймворк Keras позволяет создавать нейронные сети, организованные как произвольные ориентированные ациклические графы слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модули Inception\n",
    "В самом простом виде модуль Inception имеет три-четыре ветви, начинающиеся сверткой 1 × 1, за которой следует свертка 3 × 3, и заканчивающиеся объединением выделенных признаков. Такая организация помогает сети выделять пространственные и канальные признаки отдельно, что обеспечивает более высокую эффективность, чем при совместном их извлечении. Возможны также более сложные версии модуля Inception, которые обычно включают в себя операции объединения, разные размеры пространственной свертки (например, 5 × 5 вместо 3 × 3 в некоторых ветвях) и ветви без пространственной свертки (то есть включающие в себя только свертку 1 × 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c) \n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "output = layers.concatenate( [branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, что полная архитектура Inception V3 доступна в Keras как keras.applications .inception_v3.InceptionV3, включая веса, полученные предварительным обучением на наборе данных ImageNet. В модуле applications, во фреймворке Keras, имеется еще одна похожая модель — Xception1. Название Xception происходит от extreme inception. Это архитектура сверточных сетей, разработанная отчасти под влиянием Inception. Ее идея состоит в том, чтобы полностью разделить выделение канальных и пространственных признаков и заменить модули Inception раздельными свертками по глубине (depthwise separable convolution), состоящими из глубоких сверток (пространственных сверток, в которых каждый входной канал обрабатывается отдельно), за которыми следуют поточечные свертки (свертки 1 × 1) — фактически крайняя форма модуля Inception, в которой пространственные и канальные признаки полностью разделены. Xception имеет примерно такое же число параметров, как Inception V3, но показывает более высокую скорость работы и точность на наборе ImageNet, а также на других больших наборах данных благодаря более эффективному использованию параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Остаточные связи \n",
    "Остаточные связи решают две распространенные проблемы, затрагивающие любые крупномасштабные модели глубокого обучения: затухание градиентов и недостаточную репрезентативность. В общем случае добавление остаточных связей в любую модель, имеющую более 10 слоев, почти наверняка даст положительный результат.\n",
    "Остаточная связь заключается в передаче вывода более раннего слоя на вход более позднего слоя, вследствие чего в последовательной сети фактически создается короткий путь. \n",
    "\n",
    "Вместо объединения с более поздней активацией вывод, полученный ранее, суммируется с более поздней активацией, что предполагает равенство размеров обеих активаций. Если они имеют разные размеры, можно применить линейное преобразование для приведения формы ранней активации к форме цели (например, слой Dense без активации или, для карт сверточных признаков, свертку 1 × 1 без активации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) \n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.add([y, x]) # Добавление оригинального тензора x к выходным признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x) # Используется свертка 1 × 1 для линейного снижения размерности исходного тензора x, чтобы получить форму как у тензора y \n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НЕДОСТАТОЧНАЯ РЕПРЕЗЕНТАТИВНОСТЬ В ГЛУБОКОМ ОБУЧЕНИИ\n",
    "В модели Sequential каждый последующий слой представления строится на основе предыдущего, то есть он имеет доступ только к информации, содержащейся в активации предыдущего слоя. Если один из слоев будет слишком маленьким (например, имеет признаки со слишком низкой размерностью), тогда модель будет ограничена объемом информации, содержащимся в активациях этого слоя.\n",
    "Чтобы вам было понятнее, проведем аналогию с механизмом обработки сигнала: представьте, что у вас имеется конвейер обработки аудиосигнала, состоящий из последовательности операций, каждая из которых принимает результат предыдущей операции. Тогда, если одна операция ограничит сигнал низкочастотным диапазоном (например, 0–15 кГц), последующие операции не смогут восстановить обрезанные частоты. Если информация теряется, она теряется навсегда. Остаточные связи, путем повторного внедрения более ранней информации в последующие операции, отчасти решают эту проблему.\n",
    "## ЗАТУХАНИЕ ГРАДИЕНТА В ГЛУБОКОМ ОБУЧЕНИИ\n",
    "Алгоритм обратного распространения ошибки — основной алгоритм, используемый для обучения глубоких нейронных сетей, — основан на распространении сигнала обратной связи от вывода к ранним слоям. Если сигналу приходится распространяться через глубокий стек слоев, он может ослабнуть или даже полностью потеряться, что сделает сеть необучаемой. Эта проблема известна как затухание градиентов.\n",
    "\n",
    "Эта проблема проявляется и в глубоких, и в рекуррентных сетях с очень длинными последовательностями — в обоих случаях сигналу обратной связи приходится распространяться через длинные последовательности операций. Вы уже знакомы с решением этой проблемы, которое используется уровнем LSTM в рекуррентных сетях: оно предполагает внедрение несущего потока, распространяющего информацию параллельно главному потоку обработки. Остаточные связи помогают добиться аналогичного эффекта в глубоких сетях прямого распространения, но они еще проще: они внедряют простой линейный несущий поток параллельно главному стеку слоев, и это помогает распространить градиенты через сколь угодно глубокие стеки слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Повторное использование экземпляров слоев\n",
    "Еще одной важной особенностью функционального API является возможность повторного использования экземпляра слоя. Когда вы дважды вызываете экземпляр слоя, вместо создания нового слоя в каждом вызове повторно будут использоваться те же самые веса. Это позволяет создавать модели с общими ветвями, когда имеется несколько ветвей, совместно использующих общие знания и выполняющих одинаковые операции. Другими словами, они вместе используют общие представления и совместно обучают их на разных входных наборах.\n",
    "\n",
    "Рассмотрим модель, которая попытается оценить семантическое сходство двух предложений. Модель имеет два входа (два сравниваемых предложения) и выводит оценку в диапазоне между 0 и 1, где 0 означает полное отсутствие сходства между предложениями, а 1 — полную смысловую идентичность. \n",
    "\n",
    "В такой конфигурации два входных предложения взаимозаменяемы, потому что семантическое сходство является симметричным отношением: сходство А с Б идентично сходству Б с А. По этой причине нецелесообразно обучать две независимые модели для обработки каждого входного предложения. Предпочтительнее было бы обрабатывать оба одним слоем LSTM. Представления этого слоя LSTM (его веса) определяются на основе обоих входов одновременно. Мы называем это сиамской моделью LSTM, или общим LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32) \n",
    "\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input) \n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input) \n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1) \n",
    "\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions) \n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модели как слои\n",
    "Важно отметить, что функциональный API позволяет использовать модели как слои — фактически о моделях можно думать как о «больших слоях». Это верно для обоих классов — Sequential и Model.\n",
    "\n",
    "Простым примером практического применения повторного использования экземпляра модели может служить модель зрения, которая в качестве входа использует сдвоенную камеру: две параллельные камеры, отстоящие друг от друга на пару сантиметров (один дюйм). Такая модель может воспринимать глубину, что может пригодиться во многих приложениях. Вам не нужно создавать две независимые модели для извлечения визуальных признаков из изображений, передаваемых левой и правой камерами, перед объединением двух потоков. Низкоуровневую обработку двух входных потоков можно выполнять сообща, то есть задействовать слои, совместно использующие одни и те же веса и, соответственно, представления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "xception_base = applications.Xception(weights=None, include_top=False) # Базовая модель обработки изображения — сеть Xception (только сверточная основа)\n",
    "\n",
    "left_input = Input(shape=(250, 250, 3))  # На вход подаются изображения в формате RGB и с размером 250 × 250\n",
    "right_input = Input(shape=(250, 250, 3)) \n",
    "\n",
    "left_features = xception_base(left_input)  # Одна и та же модель вызывается дважды\n",
    "right_features = xception_base(right_input) \n",
    "\n",
    "merged_features = layers.concatenate( [left_features, right_features], axis=-1) #Объединенный набор признаков содержит информацию из правого и левого источников визуальной информации"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
